# 上（第二单元）：

第二章习题
1.简述Scala语言与Java语言的联系与区别。
答： 
联系：scala语言来源于java,scala以java的虚拟机（JVM）为运行环境，scala源码(.scala)会编译成.class文件。

两种语言之间有很多相似的地方，在一些语法上有些明显区别主要如下：

(1)beak和continue  (2)函数返回值形式  (3)异常   (4)面向对象

(5)包     (6) 面向对象编程特征之一封装、继承、多态   (7)集合

此外，scala特有的概念：

(1)过程  (2)惰性函数  (3)伴生对象   (4) apply方法  (5)特质 等等概念。

2.简述Scala语言的基本特性。

答：

（1）运行在 JVM 和 JavaScript 之上的语言（2）静态类型 

（3）混合式编程范式——面向对象编程  （4）混合式编程范式——函数式编程

（5）复杂的类型系统 （6）简洁、优雅、灵活的语法  （7）可扩展的架构


4.Scala有哪些基本数据类型和操作符？
答：
数据类型：

| Byte | 8位带符号整数 |  
| Short| 16位带符号整数 |   
| Int  | 32位带符号整数 | 
| Long | 64位带符号整数 | 
| Char | 16位无符号Unicode字符 |  
|String| Char类型的序列（字符串） |   
| Float| 32位单精度浮点数 |  
|Double| 64位双精度浮点数 |  
|Boolean| true或false |  
  
操作符：  
| 算术运算符 | +、-、*、/ | 
| 关系运算符 | >、<、==、!=、>=、<= |  
| 逻辑运算符 | &&、||、! | 
| 位运算符   | &、||、^、<<、>> | 

5在Scala里怎样定义一个变量？与Java的变量定义有什么区别？   
Scala里定义一个变量：

(1)val 变量名：数据类型=初始值 
(2)var 变量名：数据类型=初始值 
而Scala的这种语法结构与Java中“变量类型 变量名=值”的语法结构有所区别。     




9.什么是for推导式和生成器表达式？ 
  答：  
for推导式：for循环与if语句是各个编程语⾔中最常⽤的控制结构语句。

生成器表达式(generator expression)也叫生成器推导式或生成器解析式，用法与列表推导式非常相似， 
在形式上生成器推导式使用圆括号(parentheses)作为定界符，而不是列表推导式所使用的方括号(square brackets)。 

17.什么是单例对象和伴生对象？

答：Scala语言是完全面向对象的语言，所以并没有静态的概念。但是为了能够和Java语言交互，就产生了一种特殊的对象来模拟类对象，该对象为单例对象。    
    
若单例对象名与类名一致，则称该单例对象这个类的伴生对象，这个类的所有“静态”内容都可以放置在它的伴生对象中声明。      

19.简述apply方法和unapply方法的调用约定以及通常的应用场景。

答：

apply方法的调用约定：   
用括号传递给类实例或对象名一个或多个参数时，
Scala会在对应的类或者对象中查找方法名为apply并且参数列表与传入的参数一致的方法，并用传入的参数来调用该apply方法。    
apply方法应用场景：通常将其定义在类的伴生对象中。     

unapply方法的调用约定：     
可以认为unapply方法是apply方法的反向操作，apply方法接受构造参数变成对象，而unapply方法接受一个对象，从中提取值。        
unapply方法应用场景 ：   
unapply方法用于对对象进行解构操作。     

29.请描述map和flatMap的区别。

答：      
Map是将集合中的每一个元素映射到函数，然后返回新集合     
flatMap是将集合中的每一个元素的子元素映射到函数，然后返回新集合。      





# 下 （第三单元）:


第三章习题

2.spark的出现是为了解决Hadoop MapReduce的不足，试列举Hadoop MapReduce的几个缺陷,并说明Spark具备哪些优点。
答：

（1）Hadoop存在以下缺点：①表达能力有限；②磁盘IO开销大；③延迟高。      

（2）Spark主要有如下优点：      
　①Spark的计算模式也属于MapReduce，但不局限于Map和Reduce操作，还提供了多种数据集操作类型，编程模型比MapReduce更灵活；     
　②Spark提供了内存计算，中间结果直接存放内存中，带来更高的迭代运算效率；   
　③Spark基于DAG的任务调度执行机制，要优于MapReduce的迭代执行机制。      
 
4.Spark已打造出结构一体化、功能多样化的大数据生态系统，请阐述Spark的生态系统。     

答：Spark的⽣态系统既能够提供内存计算框架，也可以⽀持SQL即席查询、实时流式计算、机器学习和图计算等。
    Spark可以部署在资源管理器YARN之上，提供⼀站式的⼤数据解决⽅案。因此， Spark所提供的⽣态系统同时⽀持批处理、交互式查询和流数据处理。

7.请阐述如下Spak的几个主要概念：RDD、DAG、阶段、分区、窄依赖、宽依赖。
答：

  ① RDD：是弹性分布式数据集（Resilient Distributed Dataset）的英文缩写，是分布式内存的一个抽象概念，提供了一种高度受限的共享内存模型。 
  
  ② DAG：是Directed Acyclic Graph（有向无环图）的英文缩写，反映RDD之间的依赖关系。   
  
  ③ 阶段：是作业的基本调度单位，一个作业会分为多组任务，每组任务被称为“阶段”，或者也被称为“任务集”。      
  
  ④ 分区：一个RDD就是一个分布式对象集合，本质上是一个只读的分区记录集合，每个RDD可以分成多个分区，每个分区就是一个数据集片段。  
  
  ⑤ 窄依赖：父RDD的一个分区只被一个子RDD的一个分区所使用就是窄依赖。    
  
  ⑥ 宽依赖：父RDD的一个分区被一个子RDD的多个分区所使用就是宽依赖。      



